# Agent Guide

The “agent” is a short OpenAI-powered routine inside `backend/app.py` (`generate_analysis_report`).  
It turns raw EEG predictions into a short report that non-technical users can read.

## What the Agent Does
1. Receives the model’s probability of Major Depressive Disorder (MDD) and the top EEG feature weights generated by LIME.
2. Builds a friendly prompt that asks an expert neurologist persona to explain those numbers.
3. Calls `client.chat.completions.create` with `model="gpt-4"` (you can switch to `gpt-4o` or `gpt-3.5-turbo` if needed).
4. Returns two paragraphs of text that the backend stores alongside the prediction and shares with the frontend/PDF report.

## Configuration Checklist
- Set `OPENAI_API_KEY` inside `backend/.env`. Without it the agent is skipped and the API replies with a fallback message.
- Update `SECRET_KEY` for Flask sessions (also in `backend/.env`).
- To tweak the tone or level of detail, edit the prompt in `generate_analysis_report` (look for the multi-line `prompt = f""" ... """` block in `backend/app.py`).
- To run inference with a cheaper model, modify the `model=` parameter when creating the chat completion. Stick to models that support the Chat Completions API.

## Local Testing
Use the backend directly so you can see the agent response in the terminal:
```bash
cd backend
source venv/bin/activate
python app.py
# upload an EEG from the frontend or hit /api/eeg-analysis with curl/Postman
```
The server log prints the generated report and any OpenAI error messages. If you see `Failed to generate report`, ensure:
- The API key is valid and has enough quota.
- Your machine has internet access.
- The prompt does not exceed the model’s token limit (rare with current inputs).

## Safety & Cost Tips
- Every report is a paid OpenAI request. Budget roughly 300–600 input tokens + 200 output tokens per analysis.
- Log or cache reports only if your privacy policy allows it; EEG interpretations can be sensitive.
- Consider wrapping the `client.chat.completions.create` call in retry logic if you run batch jobs.
- If you need full observability, connect OpenAI responses to your monitoring stack (e.g., log JSON with timestamps and EEG file IDs).

## Extending the Agent
- Swap in another provider (Anthropic, Gemini) by replacing the OpenAI client call.
- Generate multilingual reports by adjusting the prompt to specify a target language.
- Return richer structured data by asking the model for JSON (remember to add validation before sending it to users).

This file should give anyone—teammates, auditors, or future-you—a quick way to understand and adjust the reporting agent.
